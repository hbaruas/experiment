{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ LLM Job Classification System - FAISS Version (Offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ctransformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Models from Local Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-downloaded Sentence Transformer model\n",
    "embedder = SentenceTransformer('D:/NLP/all-MiniLM-L6-v2/')\n",
    "\n",
    "# Load pre-downloaded Mistral-7B-Instruct LLM\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path=\"./\", \n",
    "    model_file=\"D:/NLP/LLM/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=0  # Use CPU fully\n",
    ")\n",
    "\n",
    "print(\"✅ Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare SOC Codes and Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define synthetic SOC data\n",
    "soc_data = [\n",
    "    {\"soc_code\": \"2111\", \"title\": \"Biological Scientists\", \"description\": \"Research and analysis of biological data and processes.\"},\n",
    "    {\"soc_code\": \"2122\", \"title\": \"Mechanical Engineers\", \"description\": \"Design and development of mechanical systems.\"},\n",
    "    {\"soc_code\": \"2425\", \"title\": \"Data Analysts\", \"description\": \"Data analysis, pattern recognition, and reporting.\"},\n",
    "    {\"soc_code\": \"4112\", \"title\": \"Data Entry Clerks\", \"description\": \"Inputting, updating and managing data records.\"},\n",
    "    {\"soc_code\": \"3421\", \"title\": \"Data Scientists\", \"description\": \"Advanced data modeling, machine learning, and AI research.\"},\n",
    "]\n",
    "\n",
    "# Define synthetic Data Labels\n",
    "data_labels = [\n",
    "    {\"label\": \"Data Entry\", \"description\": \"Typing, inputting, and administrative handling of data.\"},\n",
    "    {\"label\": \"Database Management\", \"description\": \"Managing SQL servers, database optimization, data warehousing.\"},\n",
    "    {\"label\": \"Data Analytics\", \"description\": \"Analyzing datasets, pattern finding, report generation.\"},\n",
    "    {\"label\": \"Data Science\", \"description\": \"Predictive modeling, machine learning, and AI development.\"}\n",
    "]\n",
    "\n",
    "print(\"✅ SOC and Label metadata prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build FAISS Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed SOC Codes\n",
    "documents_soc = [entry[\"description\"] for entry in soc_data]\n",
    "embeddings_soc = embedder.encode(documents_soc, show_progress_bar=True)\n",
    "\n",
    "# Embed Data Labels\n",
    "documents_labels = [entry[\"description\"] for entry in data_labels]\n",
    "embeddings_labels = embedder.encode(documents_labels, show_progress_bar=True)\n",
    "\n",
    "# Create FAISS indexes\n",
    "soc_index = faiss.IndexFlatL2(embeddings_soc.shape[1])\n",
    "soc_index.add(np.array(embeddings_soc))\n",
    "\n",
    "label_index = faiss.IndexFlatL2(embeddings_labels.shape[1])\n",
    "label_index.add(np.array(embeddings_labels))\n",
    "\n",
    "# Save metadata separately\n",
    "soc_metadata = soc_data\n",
    "label_metadata = data_labels\n",
    "\n",
    "print(\"✅ FAISS indexes created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Job Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_job(job_description, threshold=0.5):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Embed the incoming job description\n",
    "    embedding = embedder.encode([job_description])\n",
    "\n",
    "    # Find closest SOC code\n",
    "    distances_soc, soc_indices = soc_index.search(np.array(embedding), k=1)\n",
    "    soc_distance = distances_soc[0][0]\n",
    "    soc_result = soc_metadata[soc_indices[0][0]]\n",
    "\n",
    "    # Find closest Data Label\n",
    "    distances_label, label_indices = label_index.search(np.array(embedding), k=1)\n",
    "    label_distance = distances_label[0][0]\n",
    "    label_result = label_metadata[label_indices[0][0]]\n",
    "\n",
    "    # Threshold check (lower distance = better match)\n",
    "    if soc_distance > threshold:\n",
    "        predicted_soc_code = \"Unknown\"\n",
    "        predicted_soc_title = \"Unknown\"\n",
    "    else:\n",
    "        predicted_soc_code = soc_result[\"soc_code\"]\n",
    "        predicted_soc_title = soc_result[\"title\"]\n",
    "\n",
    "    if label_distance > threshold:\n",
    "        predicted_data_label = \"Unknown\"\n",
    "    else:\n",
    "        predicted_data_label = label_result[\"label\"]\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    return {\n",
    "        \"predicted_soc_code\": predicted_soc_code,\n",
    "        \"predicted_soc_title\": predicted_soc_title,\n",
    "        \"predicted_data_label\": predicted_data_label,\n",
    "        \"soc_distance\": soc_distance,\n",
    "        \"label_distance\": label_distance,\n",
    "        \"prediction_time_seconds\": elapsed_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_job_description = \"We are looking for someone to manage large-scale data warehouses and optimize SQL databases. Experience in database management is essential.\"\n",
    "\n",
    "result = classify_job(sample_job_description)\n",
    "\n",
    "print(\"\\n\\n===== Classification Result =====\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n✅ Job classification completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
