import requests
import pandas as pd
from tqdm import tqdm
import time
import certifi

# YOUR REED API KEY HERE
API_KEY = 'YOUR_API_KEY_HERE'

BASE_URL = 'https://www.reed.co.uk/api/1.0/search'
TARGET_JOBS = 5000
PAGE_SIZE = 25

all_jobs = []
page = 1
progress = tqdm(total=TARGET_JOBS, desc='Fetching Jobs', ncols=100)

while len(all_jobs) < TARGET_JOBS:
    params = {
        'resultsToTake': PAGE_SIZE,
        'resultsToSkip': (page - 1) * PAGE_SIZE
    }

    try:
        response = requests.get(
            BASE_URL,
            headers={'Accept': 'application/json'},
            auth=(API_KEY, ''),
            params=params,
            verify=certifi.where()
        )
    except Exception as e:
        print(f"Request failed: {e}")
        break

    if response.status_code != 200:
        print(f"Error {response.status_code}: {response.text}")
        break

    jobs = response.json().get('results', [])
    if not jobs:
        print("No more jobs returned.")
        break

    for job in jobs:
        job_id = job.get('jobId')
        title = job.get('jobTitle')
        description = job.get('jobDescription')

        if job_id and title and description:
            all_jobs.append({
                'job_id': job_id,
                'title': title,
                'description': description,
                'location': job.get('locationName'),
                'employer': job.get('employerName'),
                'salary_min': job.get('minimumSalary'),
                'salary_max': job.get('maximumSalary'),
                'currency': job.get('currency'),
                'date_posted': job.get('datePosted'),
                'url': job.get('jobUrl')
            })
            progress.update(1)
            if len(all_jobs) >= TARGET_JOBS:
                break

    page += 1
    time.sleep(0.5)

progress.close()

df = pd.DataFrame(all_jobs)
df.to_csv('reed_jobs_uk_extended.csv', index=False)
print(f"\nâœ… Saved {len(df)} jobs with extra details to 'reed_jobs_uk_extended.csv'")
