import pandas as pd
import re

file_path = "/Users/saurabhkumar/Desktop/armaghdata.txt"
output_csv = "/Users/saurabhkumar/Desktop/armaghdata.csv"

clean_rows = []

with open(file_path, "r") as f:
    for line in f:
        # Keep only lines that start with a year

        if re.match(r"^\s*\d{4}", line):  # starts with year
            line = line.strip()
            parts = re.split(r'\s+', line)

            if len(parts) >= 7:
                # Optional: REMOVE footnotes like * or # or trailing text
                # -----------------------------------------
                #Uncomment the following block to clean footnotes:
                for i in range(2, 7):  # only clean columns tmax to sun
                    parts[i] = re.sub(r"[#*]", "", parts[i])
                if len(parts) > 7:  # If extra notes like "Provisional" exist
                    parts = parts[:7]
                # -----------------------------------------

                clean_rows.append(parts[:7])

df = pd.DataFrame(clean_rows, columns=["year", "month", "tmax", "tmin", "af", "rain", "sun"])
df.to_csv(output_csv, index=False)

print(f"✅ CSV saved to: {output_csv}")


#https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data


	•	Collaborating with other teams in the division:
	•	Built an MVP using natural language processing to understand and quantify the role of data in the UK job market.
	•	Port Data Project:
	•	Publishing ship counts at major UK ports.
	•	Exploring further analysis on free ports to assess their economic impact.
	•	Land Mobility Data:
	•	Reviving work on land mobility using traffic camera data in collaboration with RDSA.
	•	Weather and Consumer Behaviour:
	•	Analysing Met Office and CEDA data to study the effect of extreme weather on:
	•	Retail footfall.
	•	Consumer behaviours (e.g. electricity payment failures, weather-linked patterns).
	•	VAT Flash Estimates:
	•	Partnering with Data Science Campus to convert the 7-day VAT flash estimate diffusion index into a numerical index.
	•	Nearing publication as part of the monthly release.



Subject: Request to Install spaCy and en_core_web_lg Model on the DAP Environment

Dear [Team/Support/Platform Operations],

I hope you’re well.

I am writing to request the installation of the Python NLP library spaCy along with the en_core_web_lg model in the DAP environment.

As part of my current work within [insert your team name or project, e.g. “the Real-Time Indicators team”], I am developing a natural language processing (NLP) pipeline to extract structured information from large volumes of unstructured job advert text. This involves identifying noun phrases, named entities, and semantic patterns relevant to labour market indicators.

To achieve this, I require:
	•	spaCy, which is a widely used industrial-strength NLP library for tokenization, part-of-speech tagging, parsing, named entity recognition, and more.
	•	en_core_web_lg, which is a pre-trained large English model for spaCy. It includes word vectors and provides higher accuracy for semantic similarity and named entity recognition tasks than the default small model.

Unfortunately, spaCy and this specific model are not currently available via the DAP’s internal artifactory or environment configuration tools. I would be very grateful if the platform team could consider making them available, as they are essential for progressing with the NLP-related elements of our analysis.

If you need any further technical details or justification for this request, I’d be happy to provide more information or arrange a short meeting.

Many thanks in advance for your help and support.

https://github.com/explosion/spacy-models/releases/tag/en_core_web_md-3.7.1

Best regards,
Saurabh Kumar
Senior Data Scientist
Office for National Statistics
